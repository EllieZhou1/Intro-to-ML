{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# ðŸ¤– Intro to Machine Learning Week 3\n",
        "\n",
        "By Ellie Zhou, August 2025\n",
        "Build a CNN to classify handwritten digits (0-9) using PyTorch!\n",
        "\n",
        "**What we'll do:**\n",
        "- Load MNIST dataset\n",
        "- Build CNN architecture  \n",
        "- Train and evaluate\n",
        "- Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup device and random seeds\n",
        "torch.manual_seed(42)  # For reproducible results\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "load-data"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Data preprocessing - prepare images for CNN\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                      # Convert PIL images to tensors (0-1 range)\n",
        "    transforms.Normalize((0.1307,), (0.3081,)) # Normalize using MNIST mean & std\n",
        "])\n",
        "\n",
        "# Load MNIST dataset - 28x28 grayscale images of handwritten digits\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)   # 60,000 training images\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)   # 10,000 test images\n",
        "\n",
        "# Data loaders - load data in batches for efficient training\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)   # Shuffle training data each epoch\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)    # No need to shuffle test data\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset):,}\")\n",
        "print(f\"Test samples: {len(test_dataset):,}\")\n",
        "\n",
        "# Show sample images to understand our data\n",
        "plt.figure(figsize=(12, 3))\n",
        "for i in range(8):\n",
        "    image, label = train_dataset[i]              # Get image tensor and label\n",
        "    plt.subplot(1, 8, i+1)                       # Create subplot\n",
        "    plt.imshow(image.squeeze(), cmap='gray')     # Display as grayscale (.squeeze() removes channel dim)\n",
        "    plt.title(f'{label}')                        # Show true digit label\n",
        "    plt.axis('off')                              # Hide axes for cleaner look\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model"
      },
      "source": [
        "## Build CNN\n",
        "\n",
        "**Architecture:** Conv â†’ Pool â†’ Conv â†’ Pool â†’ Conv â†’ FC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnn-model"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # Convolutional layers - extract features from images\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3)     # 28x28x1 â†’ 26x26x32\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)    # 13x13x32 â†’ 11x11x64\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3)    # 5x5x64 â†’ 3x3x64\n",
        "        self.pool = nn.MaxPool2d(2, 2)       # Reduces spatial dimensions by half\n",
        "\n",
        "        # Fully connected layers - for final classification\n",
        "        self.fc1 = nn.Linear(64 * 3 * 3, 128)  # Flatten conv output to 128 neurons\n",
        "        self.fc2 = nn.Linear(128, 10)          # 128 â†’ 10 classes (digits 0-9)\n",
        "        self.dropout = nn.Dropout(0.5)         # Prevent overfitting\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv blocks: convolution â†’ ReLU â†’ pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "\n",
        "        # Flatten and fully connected layers\n",
        "        x = x.view(-1, 64 * 3 * 3)  # Flatten 2D feature maps to 1D\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Create model and count parameters\n",
        "model = CNN().to(device)\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "training"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Training setup\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
        "\n",
        "# Training function - one pass through training data\n",
        "def train_epoch():\n",
        "    model.train()  # Set to training mode (enables dropout)\n",
        "    running_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for data, target in train_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()  # Calculate gradients\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        # Track statistics\n",
        "        running_loss += loss.item()\n",
        "        _, pred = torch.max(output, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (pred == target).sum().item()\n",
        "\n",
        "    return running_loss/len(train_loader), 100.*correct/total\n",
        "\n",
        "# Validation function - test without updating weights\n",
        "def validate():\n",
        "    model.eval()  # Set to evaluation mode (disables dropout)\n",
        "    test_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():  # Don't calculate gradients\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            _, pred = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (pred == target).sum().item()\n",
        "\n",
        "    return test_loss/len(test_loader), 100.*correct/total\n",
        "\n",
        "# Train for 8 epochs\n",
        "train_accs, val_accs = [], []\n",
        "\n",
        "for epoch in range(8):\n",
        "    train_loss, train_acc = train_epoch()\n",
        "    val_loss, val_acc = validate()\n",
        "\n",
        "    train_accs.append(train_acc)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    print(f'Epoch {epoch+1}: Train {train_acc:.1f}% | Val {val_acc:.1f}%')\n",
        "\n",
        "print(f'\\nFinal Test Accuracy: {val_accs[-1]:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plot-results"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Plot training progress\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_accs, 'b-', label='Training')\n",
        "plt.plot(val_accs, 'r-', label='Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.title('Training Progress')\n",
        "plt.grid(True)\n",
        "\n",
        "# Get all predictions for detailed analysis\n",
        "model.eval()\n",
        "y_pred, y_true = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        y_pred.extend(pred.cpu().numpy())\n",
        "        y_true.extend(target.cpu().numpy())\n",
        "\n",
        "# Plot confusion matrix - shows which digits get confused\n",
        "plt.subplot(1, 2, 2)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viz"
      },
      "source": [
        "## Sample Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "predictions"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Show sample predictions with confidence scores\n",
        "model.eval()\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "with torch.no_grad():\n",
        "    data, target = next(iter(test_loader))  # Get one batch\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    prob = F.softmax(output, dim=1)  # Convert to probabilities\n",
        "    _, pred = torch.max(output, 1)\n",
        "\n",
        "    # Display first 12 images with predictions\n",
        "    for i in range(12):\n",
        "        plt.subplot(3, 4, i+1)\n",
        "        plt.imshow(data[i].cpu().squeeze(), cmap='gray')\n",
        "\n",
        "        true_label = target[i].cpu().item()\n",
        "        pred_label = pred[i].cpu().item()\n",
        "        confidence = prob[i][pred_label].cpu().item()\n",
        "\n",
        "        # Color code: green for correct, red for wrong\n",
        "        color = 'green' if true_label == pred_label else 'red'\n",
        "        plt.title(f'True: {true_label}, Pred: {pred_label}\\n({confidence:.3f})', color=color)\n",
        "        plt.axis('off')\n",
        "\n",
        "plt.suptitle('Sample Predictions (Green=Correct, Red=Wrong)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "filters"
      },
      "source": [
        "## Learned Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "show-filters"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Visualize what the CNN learned - first layer filters\n",
        "filters = model.conv1.weight.data.cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "for i in range(16):  # Show first 16 of 32 filters\n",
        "    plt.subplot(2, 8, i+1)\n",
        "    plt.imshow(filters[i, 0], cmap='viridis')  # Each filter is 3x3\n",
        "    plt.title(f'Filter {i+1}', fontsize=8)\n",
        "    plt.axis('off')\n",
        "plt.suptitle('Learned Filters (First Layer)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'mnist_cnn.pth')\n",
        "print('âœ… Model saved as mnist_cnn.pth')\n",
        "\n",
        "print(f'\\nðŸŽ‰ Training Complete!')\n",
        "print(f'Final Accuracy: {val_accs[-1]:.2f}%')\n",
        "print(f'Parameters: {sum(p.numel() for p in model.parameters()):,}')"
      ]
    }
  ]
}